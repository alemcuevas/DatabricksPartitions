{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66bf44cc-9530-48d5-acad-625d2d5e691f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Decisiones de Particionamiento en Azure Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8a4597f-c9f0-418f-a49b-e66ff8215c63",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Introducción\n",
    "El particionamiento de datos es una técnica clave en sistemas distribuidos que permite dividir grandes conjuntos de datos en partes más pequeñas para mejorar el rendimiento de las consultas y la eficiencia de los recursos. Sin embargo, particionar innecesariamente o en exceso puede causar un impacto negativo en el rendimiento. Aquí vamos a evaluar cuándo particionar y cuándo no particionar en función de factores como el tamaño del dataset, las consultas que realizamos, y la cardinalidad de las columnas.\n",
    "\n",
    "### 2. Tamaño del Dataset y Decisión de Particionamiento\n",
    "**Dataset pequeño (menos de 1GB o 500,000 filas)**\n",
    "Regla general: Si tu dataset es pequeño, no tiene sentido particionarlo, ya que el overhead que se genera al gestionar particiones podría ser mayor que los beneficios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbd72dfd-d548-43a8-94d1-8009702267e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cargar un dataset pequeño\n",
    "df_small = spark.read.csv(\"/mnt/datalake/small_dataset.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Contar registros\n",
    "df_small.count()\n",
    "\n",
    "# Ejecutar consulta sin particionar\n",
    "import time\n",
    "start_time = time.time()\n",
    "df_small.groupBy(\"product_category\").sum(\"sales\").show()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "714232a6-e059-4d74-8a6b-f8ae08191eeb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Resultado esperado: Como el dataset es pequeño, no deberías ver una mejora significativa al particionar, ya que el tamaño es manejable en un solo archivo.\n",
    "\n",
    "### Dataset grande (más de 1GB o millones de filas)\n",
    "**Regla general:** Si el dataset es grande (más de 1GB o millones de filas), el particionamiento es crucial para mejorar el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5be5e4f2-acc8-4511-b260-99197b4ca821",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cargar un dataset grande\n",
    "df_large = spark.read.csv(\"/mnt/datalake/large_dataset.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Evaluar el número de registros\n",
    "df_large.count()\n",
    "\n",
    "# Particionar los datos por 'region' y 'year' y guardarlos en Delta Lake\n",
    "df_large.repartition(\"region\", \"year\").write.partitionBy(\"region\", \"year\").mode(\"overwrite\").format(\"delta\").save(\"/mnt/datalake/partitioned_data/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50c49085-a91f-43f3-9bc7-b6001130ca20",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Resultado esperado: Las consultas sobre el dataset particionado deberían mostrar mejoras en el rendimiento, ya que solo se leerán las particiones necesarias en lugar de todo el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6451656c-f7a3-4b10-bf60-c39d36244d15",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Patrón de Acceso a los Datos\n",
    "**Escaneo completo (sin particionar)**\n",
    "Si las consultas escanean todo el dataset sin filtros por columnas, el particionamiento puede ser innecesario y podría introducir sobrecarga adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45a7953a-eebe-43de-9638-445f804d82e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ejecutar una consulta que escanee todo el dataset\n",
    "start_time = time.time()\n",
    "df_large.groupBy(\"product_category\").sum(\"sales\").show()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c873648-7c35-475b-b428-45d4c7dac41f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Resultado esperado:** Si las consultas no filtran por columnas, el particionamiento no ofrece ventajas claras, ya que las particiones no se están aprovechando.\n",
    "\n",
    "### Filtrado por columnas (particionar sí es útil)\n",
    "Si las consultas frecuentes filtran por columnas específicas (como region o year), el particionamiento mejora significativamente el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d890b53c-18a4-4486-b7fe-cd6498b360f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filtrar por columna particionada (region) y medir el tiempo\n",
    "df_partitioned = spark.read.format(\"delta\").load(\"/mnt/datalake/partitioned_data/\")\n",
    "start_time = time.time()\n",
    "df_partitioned.filter(\"region = 'North' AND year = 2021\").groupBy(\"product_category\").sum(\"sales\").show()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ad3129b-618e-44ed-9ae3-f049f8fb20e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Resultado esperado:** Al particionar por las columnas filtradas, la consulta será mucho más rápida que sin particionar, ya que Spark solo leerá las particiones relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5071673b-6a74-4fb6-8bc3-fd047298826e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Cardinalidad de las Columnas y Impacto del Particionamiento\n",
    "**Alta cardinalidad (particionar sí es útil)**\n",
    "Particionar por columnas con muchos valores únicos (como region, year) distribuye los datos de manera más uniforme y mejora el paralelismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd5d9a3c-0b5c-44f2-9025-ae4832ecb650",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Particionar por 'region' y 'year' (alta cardinalidad)\n",
    "df_large.repartition(\"region\", \"year\").write.partitionBy(\"region\", \"year\").mode(\"overwrite\").parquet(\"/mnt/datalake/partitioned_by_region_year/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c22b987e-47ef-41ba-9eb0-85c6c43aaf3d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Baja cardinalidad (evitar particionamiento)**\n",
    "Si particionas por columnas con pocos valores únicos (baja cardinalidad, como gender o boolean), las particiones no aportan beneficios significativos y pueden incluso reducir el paralelismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "449995d2-acc7-4e67-a052-c7c1912c672d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Particionar por columna de baja cardinalidad (como gender)\n",
    "df_large.repartition(\"gender\").write.partitionBy(\"gender\").mode(\"overwrite\").parquet(\"/mnt/datalake/partitioned_by_gender/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a90b0a9-234c-495d-93a6-155810c1afc1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Resultado esperado:** Particionar por columnas con baja cardinalidad puede resultar en particiones grandes, lo que reduce el paralelismo y no mejora el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5973765a-f04c-4f5d-9a37-751e3715aa0c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Monitoreo del Impacto del Particionamiento\n",
    "**Spark UI:** Para cada consulta, utiliza la **Spark UI** para analizar cómo las particiones afectan el tiempo de ejecución, la cantidad de \"shuffle\", y el uso de memoria.\n",
    "\n",
    "Navega a la **Spark UI** y examina la sección de \"Jobs\" para ver cuántas particiones fueron procesadas y cuántos datos fueron \"shuffleados\" entre nodos.\n",
    "**Ganglia Metrics:** Utiliza **Ganglia** para monitorear el uso de CPU y memoria. Si el uso de recursos no mejora después de particionar, revisa tu estrategia de particionamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6f2ca89-f514-42c0-94e0-553882b01541",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Cuándo particionar los datos\n",
    "### Grandes volúmenes de datos (mayores de 1GB o millones de filas)\n",
    "\n",
    "**Razón:** Los datasets grandes tienden a requerir particiones para aprovechar el procesamiento distribuido en clústeres de Databricks y mejorar el rendimiento en consultas. Particionar permite que Spark procese datos en paralelo, distribuyendo las tareas entre nodos del clúster.\n",
    "\n",
    "**Tamaño recomendado:** Generalmente, datasets que superen 1GB o aquellos con millones de filas se benefician de particionamiento, ya que leer y procesar todo el dataset sin particiones puede ser ineficiente.\n",
    "\n",
    "**Ejemplo:** En un dataset de ventas con transacciones de varios años, particionar por year, region, o product_category ayuda a reducir el volumen de datos que Spark tiene que leer y procesar para consultas específicas.\n",
    "\n",
    "**Mejoras esperadas:** Menor tiempo de ejecución para consultas que filtran por columnas particionadas y menor uso de recursos al leer solo las particiones necesarias.\n",
    "### Consultas que filtran por columnas específicas\n",
    "\n",
    "**Razón:** Si las consultas frecuentes filtran por valores específicos (por ejemplo, year, region), particionar por esas columnas permite que Spark lea solo las particiones relevantes, en lugar de escanear todo el dataset.\n",
    "\n",
    "**Tamaño de referencia:** Si el dataset es mayor a 500MB y las consultas se basan en columnas particulares con altos valores de cardinalidad, como fechas o categorías de productos.\n",
    "\n",
    "**Mejoras esperadas:** Reducción significativa en el tiempo de consulta y mejora en el uso de recursos del clúster.\n",
    "### Optimización de almacenamiento en sistemas distribuidos\n",
    "\n",
    "**Razón:** Particionar es importante en sistemas como Azure Data Lake o S3, ya que evita la creación de un único archivo masivo que es ineficiente de procesar. En lugar de tener un archivo gigante, se dividen los datos en archivos más pequeños organizados por particiones.\n",
    "\n",
    "**Tamaño de referencia:** Datasets con varios GB o TB de datos.\n",
    "\n",
    "**Mejoras esperadas:** Mejor eficiencia en operaciones de lectura y escritura, ya que los archivos están distribuidos y segmentados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bac5c9a-0ae3-41f1-9e01-babff5de2dee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Cuándo NO particionar los datos\n",
    "### Datasets pequeños (menos de 1GB)\n",
    "\n",
    "**Razón:** Para datasets pequeños (menos de 1GB), particionar no suele ser necesario porque el overhead de crear particiones y leer varios archivos puede ser mayor que los beneficios. Spark puede procesar fácilmente datasets pequeños sin particionar.\n",
    "\n",
    "**Tamaño de referencia:** Datasets menores a 500MB o con menos de 100,000 filas.\n",
    "\n",
    "**Impacto negativo:** Si particionas un dataset pequeño, puedes crear demasiados archivos pequeños, lo que ralentiza las consultas y aumenta el overhead de administración de archivos.\n",
    "\n",
    "### Consultas que no filtran o escanean el dataset completo\n",
    "\n",
    "**Razón:** Si la mayoría de las consultas en tu dataset escanean todo el dataset sin filtrar por columnas específicas (por ejemplo, en un análisis de datos masivos o agregaciones a nivel global), particionar puede no tener beneficios significativos. De hecho, puede generar una sobrecarga adicional, ya que Spark debe procesar particiones innecesarias.\n",
    "\n",
    "**Tamaño de referencia:** Si las consultas escanean el dataset completo y no se filtran por columnas específicas, particionar puede generar más archivos pequeños y sobrecargar el sistema sin mejorar el rendimiento.\n",
    "Impacto negativo: Aumento de la sobrecarga de administración de particiones y archivos, sin mejora en el rendimiento.\n",
    "\n",
    "### Columnas con baja cardinalidad o pocos valores únicos\n",
    "\n",
    "**Razón:** Si particionas un dataset basado en una columna con pocos valores únicos (baja cardinalidad), el beneficio del particionamiento es limitado porque cada partición será grande. Por ejemplo, particionar por gender o boolean con solo dos valores (male, female o true, false) puede ser innecesario.\n",
    "\n",
    "**Impacto negativo:** Crear demasiadas particiones grandes (cada partición representando un valor de la columna) puede reducir el paralelismo y no ofrecer mejoras en el rendimiento."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "¿Particionar o no particionar",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
